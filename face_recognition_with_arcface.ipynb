{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7559862,"sourceType":"datasetVersion","datasetId":4402155}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# FACE RECOGNITION WITH ARCFACE\n\n### WITH THE BEST SUCCESS RATE\n\n#### https://arxiv.org/pdf/1804.06655.pdf","metadata":{"id":"XuYoOz_EC8CR"}},{"cell_type":"markdown","source":"* ArcFace\n* GAN","metadata":{"id":"wzCD93WsC8CT"}},{"cell_type":"markdown","source":"## 1. FACE RECOGNITION SYSTEMS","metadata":{"id":"K5snIpK5C8CT"}},{"cell_type":"markdown","source":"\n<img src=\"https://imgur.com/jUJZ4tc.png\"  width=\"600\"> <br>\n\n* **Data** : We should have images of faces for model training.\n* **Data Process** : GAN is used here.\n* **Architecture** : Model selection is done in this section.\n* **Loss** : It aims to improve education through loss functions. <br>\n\n<img src=\"https://imgur.com/xFd67t4.png\"  width=\"1000\"><br> <br>\n* **Face Alignment** : Data Cleaning.\n* **Anti - Spoofing** : Fake image detection.\n* **Face Processing** : Data preprocessing. (GAN)\n* **Feature Extraction** : Feature extraction is made from images. Focus on a specific area. For example, it outputs a vector of size 512.\n* The vector output is given to the loss functions. (Not used during testing.)\n\n","metadata":{"id":"SL9csXVEC8CU"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/0C8sHj2.png\"  width=\"800\"><br>\n","metadata":{"id":"HqEZEa0rC8CU"}},{"cell_type":"markdown","source":"### History Of Face Recognition Systems","metadata":{"id":"7c-n83UFC8CV"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/37cOL3n.png\"  width=\"1000\">","metadata":{"id":"iSjA6t0IC8CV"}},{"cell_type":"markdown","source":"### Modern Face Recognition Deep Learning Models","metadata":{"id":"VBt5i4znC8CV"}},{"cell_type":"markdown","source":"##### ImageNet Classification with Deep Convolutional Neural Networks (Details of the AlexNet model)\n\nhttps://papers.nips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n\n##### Very Deep Convolutional Networks for Large-Scale Image Recognition (VGG Networks)\n\nhttps://arxiv.org/pdf/1409.1556.pdf\n\n##### Deep Residual Learning for Image Recognition (ResNet)\n\nhttps://arxiv.org/pdf/1512.03385.pdf","metadata":{"id":"bkMMSkZ0C8CV"}},{"cell_type":"markdown","source":"#### 1- Alexnet","metadata":{"id":"SH88ZpTYC8CV"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/ZL5xBvr.png\"  width=\"400\"> <br>\n* The first layer has 96 **filters** of 11x11. With **max-pooling** the **feature map** is halved. The size of a **256x256** image is reduced to **128x128**.\n* The output of the layers is used as input for the next layer.\n* The second layer has 5x5 filters and the next layers have 3x3 filters.\n* In the last part of the model, there are 3 **fully-connected layers**.\n\n","metadata":{"id":"evbvIeGlC8CV"}},{"cell_type":"markdown","source":"#### 2- VGGNet","metadata":{"id":"Yv5nS97aC8CW"}},{"cell_type":"markdown","source":"\n<img src=\"https://imgur.com/X2htpH4.png\"  width=\"800\">  <br>\n* It has been more successful than Alexnet.\n* The disadvantage compared to modern models is the fully-connected layers at the end. \n* Because of these layers, it contains a lot of parameters. It takes up more space than modern models. It works more slowly.\n\n","metadata":{"id":"xjvfHfSvC8CW"}},{"cell_type":"markdown","source":"#### GoogleNet & ResNet","metadata":{"id":"pyMW1mM8C8CW"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/rV6eIyo.png\"  width=\"800\"> <br>\n* GoogleNet has resolved parameter redundancy.\n* Convolutions of 1x1 change the size of the feature map, which results in models that require fewer parameters.\n* ResNet enables the creation of deeper models.\n* The highest success rate in face recognition was obtained using the ResNet model.","metadata":{"id":"COYSF3B3C8CW"}},{"cell_type":"markdown","source":"\n<img src=\"https://imgur.com/OMqR2Oj.png\"  width=\"800\"> <br>\n\n* At the bottom are the most successful models of the time.\n","metadata":{"id":"HeXS_jvhC8CX"}},{"cell_type":"markdown","source":"### Face Recognition Data Sets","metadata":{"id":"n6Gp9i2mC8CX"}},{"cell_type":"markdown","source":"##### The Devil of Face Recognition is in the Noise\n\nhttps://arxiv.org/pdf/1807.11649.pdf\n","metadata":{"id":"qF8aQn-1C8CX"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/Uk0EcYK.png\"  width=\"800\"> <br>\n\n- The ones in red are the **training sets** and the other colors are the **test data sets**.\n- In training, we will use **LFW** for the test set and **MS-celeb-1M** (Microsoft's famous pictures) datasets for the training set.\n","metadata":{"id":"Zzh65HfmC8CX"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/lGioF2l.png\"  width=\"600\"> <br>\n- Models trained with many users have higher performance rates.","metadata":{"id":"tDqGFjWXC8CX"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/gMgHqqF.png\"  width=\"800\"> <br>\n- It includes how many different ids and images it contains.\n- **Source** : indicates how it was obtained.\n- **Cleaned** : indicates how it is preprocessed.\n\n","metadata":{"id":"DpClDoeRC8CX"}},{"cell_type":"markdown","source":"### LOSS FUNCTIONS","metadata":{"id":"aXBL7_IGC8CX"}},{"cell_type":"markdown","source":"##### ArcFace: Additive Angular Margin Loss for Deep Face Recognition\nhttps://arxiv.org/pdf/1801.07698.pdf\n","metadata":{"id":"xYhECtfFC8CY"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/N1H7uF5.png\"  width=\"920\"> <br>\n\n- Red : indicates those using **Softmax** lost function.\n- Green : indicates those using **Euclidean Distance-Based** lost function.\n- Blue : indicates those using **Angular Margin Based** lost function.\n- Yellow : indicates those using **Softmax Variations**","metadata":{"id":"52s3K4mvC8CY"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/PvEuNPC.png\"  width=\"920\"> <br>\n- **Softmax** loss functions are often used in deep learning.\n- However, for systems with high intra-class appearance variation, such as face recognition, softmax is not optimized.\n- ArcFace extracts distinctive features from face images with the **Angular Margin Loss** proposal.\n- The **purpose** of the proposed method (angular margin) is to make our model learn better during training by adding a penalty margin between the images of different users while collecting the same images in the same region in a space plane.\n- Figures a and b on the right show the training results using different loss functions.\n- Each individual color represents a different class.\n- ArcFace has done a better job of keeping **different classes in different regions** in space.","metadata":{"id":"GuUm1JxnC8CY"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/X4Cui7C.png\"  width=\"920\"> <br>\n- The figure shows a deep learning model trained using ArcFace.\n- The variable x denotes features and w denotes normalized weights.\n- The **first part** represents the model, while the **middle part** shows the addition of the **angular margin penalty**. The other parts are identical to previous studies.\n","metadata":{"id":"XLJfUrbWC8CY"}},{"cell_type":"markdown","source":"<img src=\"https://imgur.com/5oJnXNc.png\"  width=\"400\"> <br>\n- Different methods are tested and compared on LFW test data.\n- **Data Set :** MS1MV2(Microsoft 1 Million)  -  **Model :** ResNet100  -  **Loss Function** : ArcFace   --> highest success rate\n","metadata":{"id":"EeoH5OkNC8CY"}},{"cell_type":"markdown","source":"## 2. PROJECT","metadata":{"id":"XpEY9KHNC8CY"}},{"cell_type":"markdown","source":"#### Ön Çalışma\n##### PyTorch -  Classification Application with CIFAR10\nhttps://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\n\n---","metadata":{"id":"0vad9JxiC8CY"}},{"cell_type":"markdown","source":"##### ArcFace / backbone / arcfacenet.py  : MODEL\n- A ResNet-based model\n- An adapted model for face recognition\n##### ArcFace / data /\n- It includes code on how Test and Training data can be loaded.\n##### ArcFace / dataset : MS1M\n- Microsoft 1 Million (A certain part of it) : Full model training takes weeks!.\n##### ArcFace / dataset : lfw...\n- Test data. To be used for testing the model after model training\n##### ArcFace / margin / ArcMarginProduct.py\n- Python script containing ArcFace margin codes.\n##### ArcFace / util / utils.py\n- Here are a few functions we will use during the training.\n---","metadata":{"id":"gwPG1YkwC8CZ"}},{"cell_type":"markdown","source":"### LIBRARIES","metadata":{"id":"hNIxFUAFC8CZ"}},{"cell_type":"code","source":"# import py files(data,margin,backbone...) for kaggle\nimport sys\nsys.path.append('/kaggle/input/arcface/')\n\n# file operations\nimport os\nfrom pathlib import Path\n\n# training data visualization\nfrom tqdm import tqdm\n\n# configuration\nfrom easydict import EasyDict as edict\n\n# pytorch\nimport torch\nimport torch.nn as nn       # functions required for neural networks\nimport torch.optim as optim\nimport torchvision.utils as vutils\nfrom torchvision import transforms as trans\n\n\n# data uploading\nfrom data.ms1m import get_train_loader\nfrom data.lfw import LFW\n\n# MODEL\nfrom backbone.arcfacenet import SEResNet_IR\nfrom margin.ArcMarginProduct import ArcMarginProduct\n\nfrom util.utils import save_checkpoint, test\n","metadata":{"id":"O01ljtXeC8CZ","execution":{"iopub.status.busy":"2024-02-06T06:37:59.385582Z","iopub.execute_input":"2024-02-06T06:37:59.386232Z","iopub.status.idle":"2024-02-06T06:38:03.834902Z","shell.execute_reply.started":"2024-02-06T06:37:59.386197Z","shell.execute_reply":"2024-02-06T06:38:03.833884Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### CONFIGURATION","metadata":{"id":"dbIzFzWKC8Ca"}},{"cell_type":"markdown","source":"#### Batch Size & Learning Rate & Epoch\n- **Batch Size :** number of images given to the model. (In one iteration the model is given all the images up to the batch size.)\n- **Epoch :** Number of times all images are shown to the model. (Number of iterations)\n- 1 Epoch = means that the Model sees all the pictures.\n- There is a linear relationship between **Learning Rate** and **Batch Size**.\n- If the Batch Size is **reduced**, the Learning Rate should also be **reduced.**\n- If the number of images given in each iteration decreases, the Learning Rate should also be decreased as the **measurements will become more precise**.\n- So the progress step should be reduced.","metadata":{"id":"80Z4CLTTC8Ca"}},{"cell_type":"code","source":"conf = edict()\n\nconf.train_root = '/kaggle/input/arcface/dataset/MS1M'\nconf.lfw_test_root = '/kaggle/input/arcface/dataset/lfw_aligned_112'\nconf.lfw_file_list = '/kaggle/input/arcface/dataset/lfw_pair.txt'\n\nconf.mode = 'se_ir'   # 'ir' : ResNet based , 'se_ir' : It includes se blocks as well as ResNet blocks.\nconf.depth = 50       # arcfacenet.py > def get_blocks(num_layers) : 50 - 100 - 152 can be selected. (DEPTH)\n                      # If depth = 100 it may be better to use ir mode.\nconf.margin_type = 'ArcFace'\nconf.feature_dim = 512   # specifies what size vector to output when an image is given to the model. According to the article : 512.\nconf.scale_size = 32.0\nconf.batch_size = 96     # number of images given to the model. (16 can be selected if the video card memory is low).\nconf.lr = 0.01\nconf.milestones = [8,10,12] # reduces Learning Rate at epochs 8, 10 and 12 (to reduce train loss)\nconf.total_epoch = 14\n\n# SAVING CHECKPOINTS & MODELS\nconf.save_folder = './saved'\nconf.save_dir = os.path.join(conf.save_folder, conf.mode + '_' + str(conf.depth))       # ./saved/se_ir_50\n# When the settings in the configuration change, the file name will also change. (we can add different features)\n\n# GPU\nconf.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # If you have an Nvidia video card, use GPU or CPU.\nconf.num_workers = 4       # how many workers we want to use on the GPU to load the data.\nconf.pin_memory = True\n\n\n# WARNING : WHEN THESE VALUES ARE SELECTED, THE VIDEO CARD HOLDS APPROXIMATELY 6GB-12GB OF DATA.","metadata":{"id":"cfi6YqX5C8Ca","execution":{"iopub.status.busy":"2024-02-06T09:01:33.448876Z","iopub.execute_input":"2024-02-06T09:01:33.449542Z","iopub.status.idle":"2024-02-06T09:01:33.458544Z","shell.execute_reply.started":"2024-02-06T09:01:33.449508Z","shell.execute_reply":"2024-02-06T09:01:33.457613Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"os.makedirs(conf.save_dir, exist_ok = True)     # If saved folder does not exist, create it.","metadata":{"id":"WWjux16IC8Cb","execution":{"iopub.status.busy":"2024-02-06T06:38:03.902227Z","iopub.execute_input":"2024-02-06T06:38:03.902578Z","iopub.status.idle":"2024-02-06T06:38:03.914981Z","shell.execute_reply.started":"2024-02-06T06:38:03.902550Z","shell.execute_reply":"2024-02-06T06:38:03.914126Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### UPLOADING DATA","metadata":{"id":"sCQ8jscQC8Cb"}},{"cell_type":"code","source":"\n# DATA AUGMENTATION : When training the model, it is a machine learning technique used to reduce overfitting by training models on several \n# slightly modified copies of existing data. Below is the transformation section.\n\ntransform = trans.Compose([               # Compose combines multiple transforms if there is more than one.\n    trans.ToTensor(),        # toTensor > allows us to save the images we receive as Tensor and give them to the model.\n    # range [0,255] -> [0.0, 1.0]  If rgb is between 0-255, it is scaled as 0-1 and saved as a tensor.\n\n    # NORMALIZATION : normalization of any prominence or brightness in a channel.\n    trans.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n    # We give values for channels r,g,b. (aim: to train more resilient models)\n\n])\n\ntrainloader, class_num = get_train_loader(conf)\n","metadata":{"id":"h8Xvl3lbC8Cb","outputId":"34e8c744-aa64-45fc-df6e-1ef6a981637d","execution":{"iopub.status.busy":"2024-02-06T09:04:12.079935Z","iopub.execute_input":"2024-02-06T09:04:12.080772Z","iopub.status.idle":"2024-02-06T09:04:12.412050Z","shell.execute_reply.started":"2024-02-06T09:04:12.080738Z","shell.execute_reply":"2024-02-06T09:04:12.411057Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print('number of id : ', class_num)","metadata":{"id":"resOCVCzC8Cb","outputId":"8096a9c5-54f6-4b28-f602-595b1062d403","execution":{"iopub.status.busy":"2024-02-06T06:38:09.819904Z","iopub.execute_input":"2024-02-06T06:38:09.820265Z","iopub.status.idle":"2024-02-06T06:38:09.825323Z","shell.execute_reply.started":"2024-02-06T06:38:09.820238Z","shell.execute_reply":"2024-02-06T06:38:09.824377Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"number of id :  200\n","output_type":"stream"}]},{"cell_type":"code","source":"print(trainloader.dataset)","metadata":{"id":"lSXB2-QaC8Cj","outputId":"613d7b9f-6f22-42a6-a046-0b6e917f6187","execution":{"iopub.status.busy":"2024-02-06T06:38:09.826375Z","iopub.execute_input":"2024-02-06T06:38:09.826642Z","iopub.status.idle":"2024-02-06T06:38:09.836035Z","shell.execute_reply.started":"2024-02-06T06:38:09.826619Z","shell.execute_reply":"2024-02-06T06:38:09.835173Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Dataset ImageFolder\n    Number of datapoints: 29148\n    Root location: /kaggle/input/arcface/dataset/MS1M\n    StandardTransform\nTransform: Compose(\n               RandomHorizontalFlip(p=0.5)\n               ToTensor()\n               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n           )\n","output_type":"stream"}]},{"cell_type":"code","source":"# we do the same for the test data:\nlfwdataset = LFW(conf.lfw_test_root, conf.lfw_file_list, transform = transform)\n# Get the lfw_test_root data, get the lfw_file_list labels and apply the transform.\n\nlfwloader = torch.utils.data.DataLoader(lfwdataset, batch_size = 128, num_workers = conf.num_workers)\n# The batch_size standard for lfw is usually 128.","metadata":{"id":"LVSP31jmC8Cj","execution":{"iopub.status.busy":"2024-02-06T06:38:09.838042Z","iopub.execute_input":"2024-02-06T06:38:09.838401Z","iopub.status.idle":"2024-02-06T06:38:09.858255Z","shell.execute_reply.started":"2024-02-06T06:38:09.838371Z","shell.execute_reply":"2024-02-06T06:38:09.857598Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### MODEL","metadata":{"id":"0_kFus9SC8Ck"}},{"cell_type":"code","source":"print(conf.device)\n# if the output is cuda you have an nvidia video card and you can use GPU.","metadata":{"id":"JGoQ23yJC8Ck","outputId":"7256d89d-e363-414c-f34e-11ffaa607473","execution":{"iopub.status.busy":"2024-02-06T09:05:29.074793Z","iopub.execute_input":"2024-02-06T09:05:29.075522Z","iopub.status.idle":"2024-02-06T09:05:29.080525Z","shell.execute_reply.started":"2024-02-06T09:05:29.075488Z","shell.execute_reply":"2024-02-06T09:05:29.079512Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"# we create the model and send it to the device.\nnet = SEResNet_IR(conf.depth, feature_dim = conf.feature_dim, mode = conf.mode).to(conf.device)\n\nmargin = ArcMarginProduct(conf.feature_dim, class_num).to(conf.device) # ArcFace Loss Model\n# The loss function works like a model.\n","metadata":{"id":"425XhkqPC8Ck","execution":{"iopub.status.busy":"2024-02-06T06:38:11.716021Z","iopub.execute_input":"2024-02-06T06:38:11.716796Z","iopub.status.idle":"2024-02-06T06:38:12.368406Z","shell.execute_reply.started":"2024-02-06T06:38:11.716767Z","shell.execute_reply":"2024-02-06T06:38:12.367281Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(net)","metadata":{"id":"cm-2OgGxC8Ck","outputId":"1630ee85-d40f-4ef2-a188-90e1aff98b5f","execution":{"iopub.status.busy":"2024-02-06T06:38:13.458795Z","iopub.execute_input":"2024-02-06T06:38:13.459644Z","iopub.status.idle":"2024-02-06T06:38:13.467628Z","shell.execute_reply.started":"2024-02-06T06:38:13.459613Z","shell.execute_reply":"2024-02-06T06:38:13.466733Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"SEResNet_IR(\n  (input_layer): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): PReLU(num_parameters=64)\n  )\n  (output_layer): Sequential(\n    (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): Dropout(p=0.4, inplace=False)\n    (2): Flatten()\n    (3): Linear(in_features=25088, out_features=512, bias=True)\n    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (body): Sequential(\n    (0): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=64)\n        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (1): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=64)\n        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (2): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=64)\n        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (3): BottleNeck_IR_SE(\n      (shortcut_layer): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (res_layer): Sequential(\n        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=128)\n        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (4): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=128)\n        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (5): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=128)\n        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (6): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=128)\n        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (7): BottleNeck_IR_SE(\n      (shortcut_layer): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (res_layer): Sequential(\n        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (8): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (9): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (10): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (11): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (12): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (13): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (14): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (15): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (16): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (17): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (18): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (19): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (20): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=256)\n        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (21): BottleNeck_IR_SE(\n      (shortcut_layer): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (res_layer): Sequential(\n        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=512)\n        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (22): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=512)\n        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (23): BottleNeck_IR_SE(\n      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n      (res_layer): Sequential(\n        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): PReLU(num_parameters=512)\n        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (6): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n# function that calculates the loss between the calculated output and the actual output.","metadata":{"id":"uoRhbboKC8Ck","execution":{"iopub.status.busy":"2024-02-06T06:38:19.283491Z","iopub.execute_input":"2024-02-06T06:38:19.284192Z","iopub.status.idle":"2024-02-06T06:38:19.288459Z","shell.execute_reply.started":"2024-02-06T06:38:19.284161Z","shell.execute_reply":"2024-02-06T06:38:19.287375Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.SGD([ # SGD(Stochastic Gradient Descent)\n# SGD is an iterative optimization process that searches for an objective function with an optimum value (Minimum/Maximum).\n    {'params': net.parameters(), 'weight_decay':5e-4},\n    # We give the model parameters (BatchNorm2d, Conv2d, PReLU...) to the optimizer. The optimizer updates them in each iteration.\n    # weight_decay is a method used like dropout to prevent overfitting.\n\n    {'params': margin.parameters(), 'weight_decay':5e-4},\n    # We give the parameters of the loss function.\n\n], lr = conf.lr, momentum = 0.9, nesterov = True)\n# Stochastic Gradient Descent works slowly. When combined with the momentum value, we can get a fast result.\n# nesterov : in the background we indicate how the gradients should be calculated.\n\n# Since these parameters are learnable parameters, we ensure that they are updated during training.","metadata":{"id":"R_Dmdqn1C8Cl","execution":{"iopub.status.busy":"2024-02-06T09:08:09.019907Z","iopub.execute_input":"2024-02-06T09:08:09.020295Z","iopub.status.idle":"2024-02-06T09:08:09.028220Z","shell.execute_reply.started":"2024-02-06T09:08:09.020264Z","shell.execute_reply":"2024-02-06T09:08:09.027155Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(optimizer)","metadata":{"id":"xCTPTmbfC8Cl","outputId":"8e9b457d-5775-447f-96a4-42f9a2546c0e","execution":{"iopub.status.busy":"2024-02-06T06:38:21.148203Z","iopub.execute_input":"2024-02-06T06:38:21.148568Z","iopub.status.idle":"2024-02-06T06:38:21.153348Z","shell.execute_reply.started":"2024-02-06T06:38:21.148539Z","shell.execute_reply":"2024-02-06T06:38:21.152390Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"SGD (\nParameter Group 0\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 0.01\n    maximize: False\n    momentum: 0.9\n    nesterov: True\n    weight_decay: 0.0005\n\nParameter Group 1\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 0.01\n    maximize: False\n    momentum: 0.9\n    nesterov: True\n    weight_decay: 0.0005\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"1. parametre grubu modelin ağırlıklarını güncellerken, 2. parametre grubu ArcFace'in(margin) ağırlıklarını günceller.","metadata":{"id":"PHd44ZNDC8Cl"}},{"cell_type":"code","source":"def schedule_lr():\n    for params in optimizer.param_groups:\n        params['lr'] /=10\n    print(optimizer, flush = True)   # we print to check the optimizer each time the function is called.","metadata":{"id":"ZYIGiYzZC8Cl","execution":{"iopub.status.busy":"2024-02-06T09:08:25.510125Z","iopub.execute_input":"2024-02-06T09:08:25.510914Z","iopub.status.idle":"2024-02-06T09:08:25.515800Z","shell.execute_reply.started":"2024-02-06T09:08:25.510878Z","shell.execute_reply":"2024-02-06T09:08:25.514666Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### TRAINING","metadata":{"id":"3QdWLgYQC8Cl"}},{"cell_type":"code","source":"best_acc = 0\n\nfor epoch in range (1,conf.total_epoch+1):\n    net.train()\n\n    # net.eval()\n    print('epoch {}/{}'.format(epoch,conf.total_epoch))\n\n    if epoch == conf.milestones[0]: # 8\n        schedule_lr()\n    if epoch == conf.milestones[1]: # 10\n        schedule_lr()\n    if epoch == conf.milestones[2]: # 12\n        schedule_lr()\n\n    for data in tqdm(trainloader):\n        img, label = data[0].to(conf.device), data[1].to(conf.device)\n        optimizer.zero_grad()\n\n        logits = net(img)\n        output = margin(logits,label)\n        total_loss = criterion(output,label)\n        total_loss.backward()\n        optimizer.step()\n\n    # test\n\n    net.eval()\n    lfw_acc = test(conf, net, lfwdataset, lfwloader)\n    print('\\nLFW: {:.4f} | train_loss: {:.4f}\\n'.format(lfw_acc, total_loss.item()))\n\n    is_best = lfw_acc > best_acc\n    best_acc = max(lfw_acc, best_acc)\n\n    save_checkpoint({\n        'epoch' : epoch,\n        'net_state_dict' : net.state_dict(),\n        'margin_state_dict' : margin.state_dict(),\n        'best_acc' : best_acc\n    }, is_best, checkpoint = conf.save_dir)\n\n","metadata":{"scrolled":true,"id":"pSghLg8iC8Cm","outputId":"ede3a883-533b-4354-84fc-5c5549ace323","execution":{"iopub.status.busy":"2024-02-06T06:38:24.459765Z","iopub.execute_input":"2024-02-06T06:38:24.460180Z","iopub.status.idle":"2024-02-06T07:55:37.367971Z","shell.execute_reply.started":"2024-02-06T06:38:24.460146Z","shell.execute_reply":"2024-02-06T07:55:37.366723Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"epoch 1/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:02<00:00,  1.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.7798 | train_loss: 10.4869\n\nbest model saved\n\nepoch 2/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:07<00:00,  1.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8138 | train_loss: 7.3863\n\nbest model saved\n\nepoch 3/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:08<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8282 | train_loss: 5.0021\n\nbest model saved\n\nepoch 4/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:09<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8452 | train_loss: 4.5683\n\nbest model saved\n\nepoch 5/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:09<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8553 | train_loss: 4.1904\n\nbest model saved\n\nepoch 6/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:10<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8620 | train_loss: 1.6346\n\nbest model saved\n\nepoch 7/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:08<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8637 | train_loss: 2.9025\n\nbest model saved\n\nepoch 8/14\nSGD (\nParameter Group 0\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 0.001\n    maximize: False\n    momentum: 0.9\n    nesterov: True\n    weight_decay: 0.0005\n\nParameter Group 1\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 0.001\n    maximize: False\n    momentum: 0.9\n    nesterov: True\n    weight_decay: 0.0005\n)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:08<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8722 | train_loss: 1.0106\n\nbest model saved\n\nepoch 9/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:08<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8737 | train_loss: 0.3112\n\nbest model saved\n\nepoch 10/14\nSGD (\nParameter Group 0\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 0.0001\n    maximize: False\n    momentum: 0.9\n    nesterov: True\n    weight_decay: 0.0005\n\nParameter Group 1\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 0.0001\n    maximize: False\n    momentum: 0.9\n    nesterov: True\n    weight_decay: 0.0005\n)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:08<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8765 | train_loss: 0.8469\n\nbest model saved\n\nepoch 11/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:08<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8753 | train_loss: 0.2048\n\nepoch 12/14\nSGD (\nParameter Group 0\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 1e-05\n    maximize: False\n    momentum: 0.9\n    nesterov: True\n    weight_decay: 0.0005\n\nParameter Group 1\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 1e-05\n    maximize: False\n    momentum: 0.9\n    nesterov: True\n    weight_decay: 0.0005\n)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:08<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8775 | train_loss: 0.5172\n\nbest model saved\n\nepoch 13/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:08<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8763 | train_loss: 0.9107\n\nepoch 14/14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 304/304 [04:08<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLFW: 0.8770 | train_loss: 0.4790\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### SOTA : the State Of The Art\n1. Working with the complete MS1M dataset\n2. conf.mode = 'ir'\n3. conf.depth = '100'\n4. conf.total_epoch = 20\n5. conf.milestones = [12,16,18]\n\nlfw = gives an accuracy of 99.83%. (is the best rate ever obtained.)\n- It takes 5 days with two v100(32GB).\n\nNOTE : MobileFaceNet can be used to run the trained model on a device (mobile etc.).","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"8qz7BCK3C8Cm"},"execution_count":null,"outputs":[]}]}